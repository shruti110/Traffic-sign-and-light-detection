{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras \n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cv2 import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import img_to_array, img_to_array, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Work/Final Project/Code and Dataset/Messidor dataset/(2 label bal)messidor combined labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10060\\3467300180.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Work/Final Project/Code and Dataset/Messidor dataset/(2 label bal)messidor combined labels.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Work/Final Project/Code and Dataset/Messidor dataset/(2 label bal)messidor combined labels.csv'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"D:/Work/Final Project/Code and Dataset/Messidor dataset/(2 label bal)messidor combined labels.csv\")\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'level'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10060\\2969437981.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_train_full\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'level'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'level'"
     ]
    }
   ],
   "source": [
    "df_train_full=df_train\n",
    "df_train = pd.Series(df_train['level'])\n",
    "print(df_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10060\\399805158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(\"Number of classes before : \"+ str(y_train.shape[1]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of classes and labels : \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2753\u001b[0m     \"\"\"\n\u001b[0;32m   2754\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[1;32m-> 2755\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils as nu\n",
    "\n",
    "#print(\"Number of classes before : \"+ str(y_train.shape[1]))\n",
    "df_train=nu.to_categorical(df_train)\n",
    "\n",
    "print(\"Number of classes and labels : \" + str(df_train.shape))\n",
    "num_classes=df_train.shape[1]\n",
    "print(df_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size1 = 786\n",
    "im_size2 = 786\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes and labels : (0,)\n"
     ]
    }
   ],
   "source": [
    "df_test = []\n",
    "df_test = df_train_full[:]\n",
    "i=0\n",
    "print(\"Number of classes and labels : \" + str(df_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "dir_proc = \"/Users/shubh/Desktop/Final Project/Code and Dataset/Messidor dataset/Combined messidor images/preprocessed_test_images/\"\n",
    "i=0\n",
    "for f, breed in tqdm(df_test.values):\n",
    "    try:\n",
    "        #print(f)\n",
    "        #f=\"20051019_38557_0100_PP\"\n",
    "        img = cv2.imread(('D:/Work/Final Project/Code and Dataset/Messidor dataset/preprocessed_1/{}.png'.format(f)))\n",
    "        #img_scaled =img\n",
    "        img_scaled = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n",
    "        #arr = image.img_to_array(img)\n",
    "        label = df_train[i]\n",
    "        x_train.append(img_scaled)\n",
    "        y_train.append(label)\n",
    "        #print(label)\n",
    "        i += 1\n",
    "    except:\n",
    "        print(\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 270 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10060\\3847041684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m270\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 270 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print(df_train[270])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1201, 256, 256, 3)\n",
      "(1201, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train=np.asarray(x_train,dtype='float32')\n",
    "y_train=np.asarray(y_train,dtype='float32')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data now : (1201, 256, 256, 3)\n",
      "height of training data : 256\n"
     ]
    }
   ],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "#reshape the data to format accepted by Keras\n",
    "#i=0\n",
    "#while(1):\n",
    "#    x_train[i]=x_train[i].reshape(img_rows,img_cols,1)\n",
    " #   x_train[i]=x_train[i].astype('float32')\n",
    " #   x_train[i]/=255\n",
    " #   i+=1\n",
    " #   if(i==199):\n",
    " #       break\n",
    "x_train=x_train.reshape(x_train.shape[0],img_rows,img_cols,3)\n",
    "#x_test=x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
    "\n",
    "#the shape of a single image to feed to 1st layer of CNN\n",
    "input_shape=(img_rows,img_cols,3)\n",
    "\n",
    "#convert to float 32 as CNN requires float 32 data\n",
    "x_train=x_train.astype('float32')\n",
    "#x_test=x_test.astype('float32')\n",
    "\n",
    "#normalize\n",
    "x_train/=255\n",
    "#x_test/=255\n",
    "\n",
    "\n",
    "print(\"shape of the data now : \" + str(x_train.shape))\n",
    "print(\"height of training data : \"+ str(x_train[1].shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',x_train[18])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[18].shape)\n",
    "#print(x_test[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training labels : 1201\n",
      "Number of training images : 1201\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of training labels : \" + str(len(y_train))+\"\\nNumber of training images : \"+str(len(x_train)))\n",
    "\n",
    "#print(\"Number of testing labels : \" + str(len(y_test))+\"\\nNumber of testing images : \"+str(len(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',X_train[18])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data now : (960, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the data now : \" + str(X_train.shape))\n",
    "#print(\"shape of the data now : \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 ZeroPadding2D False\n",
      "2 Conv2D False\n",
      "3 BatchNormalization False\n",
      "4 ReLU False\n",
      "5 DepthwiseConv2D False\n",
      "6 BatchNormalization False\n",
      "7 ReLU False\n",
      "8 Conv2D False\n",
      "9 BatchNormalization False\n",
      "10 ReLU False\n",
      "11 ZeroPadding2D False\n",
      "12 DepthwiseConv2D False\n",
      "13 BatchNormalization False\n",
      "14 ReLU False\n",
      "15 Conv2D False\n",
      "16 BatchNormalization False\n",
      "17 ReLU False\n",
      "18 DepthwiseConv2D False\n",
      "19 BatchNormalization False\n",
      "20 ReLU False\n",
      "21 Conv2D False\n",
      "22 BatchNormalization False\n",
      "23 ReLU False\n",
      "24 ZeroPadding2D False\n",
      "25 DepthwiseConv2D False\n",
      "26 BatchNormalization False\n",
      "27 ReLU False\n",
      "28 Conv2D False\n",
      "29 BatchNormalization False\n",
      "30 ReLU False\n",
      "31 DepthwiseConv2D False\n",
      "32 BatchNormalization False\n",
      "33 ReLU False\n",
      "34 Conv2D False\n",
      "35 BatchNormalization False\n",
      "36 ReLU False\n",
      "37 ZeroPadding2D False\n",
      "38 DepthwiseConv2D False\n",
      "39 BatchNormalization False\n",
      "40 ReLU False\n",
      "41 Conv2D False\n",
      "42 BatchNormalization False\n",
      "43 ReLU False\n",
      "44 DepthwiseConv2D False\n",
      "45 BatchNormalization False\n",
      "46 ReLU False\n",
      "47 Conv2D False\n",
      "48 BatchNormalization False\n",
      "49 ReLU False\n",
      "50 DepthwiseConv2D False\n",
      "51 BatchNormalization False\n",
      "52 ReLU False\n",
      "53 Conv2D False\n",
      "54 BatchNormalization False\n",
      "55 ReLU False\n",
      "56 DepthwiseConv2D False\n",
      "57 BatchNormalization False\n",
      "58 ReLU False\n",
      "59 Conv2D False\n",
      "60 BatchNormalization False\n",
      "61 ReLU False\n",
      "62 DepthwiseConv2D False\n",
      "63 BatchNormalization False\n",
      "64 ReLU False\n",
      "65 Conv2D False\n",
      "66 BatchNormalization False\n",
      "67 ReLU False\n",
      "68 DepthwiseConv2D False\n",
      "69 BatchNormalization False\n",
      "70 ReLU False\n",
      "71 Conv2D False\n",
      "72 BatchNormalization False\n",
      "73 ReLU False\n",
      "74 ZeroPadding2D False\n",
      "75 DepthwiseConv2D False\n",
      "76 BatchNormalization False\n",
      "77 ReLU False\n",
      "78 Conv2D False\n",
      "79 BatchNormalization False\n",
      "80 ReLU False\n",
      "81 DepthwiseConv2D False\n",
      "82 BatchNormalization False\n",
      "83 ReLU False\n",
      "84 Conv2D False\n",
      "85 BatchNormalization False\n",
      "86 ReLU False\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 257, 257, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 128, 128, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 128, 128, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 128, 128, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 129, 129, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 64, 64, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 64, 64, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 64, 64, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 64, 64, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 65, 65, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 32, 32, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 32, 32, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 32, 32, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 33, 33, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 16, 16, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 16, 16, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 16, 16, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 16, 16, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 16, 16, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 16, 16, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 16, 16, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 16, 16, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 16, 16, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 16, 16, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 16, 16, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 17, 17, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 8, 8, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 8, 8, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 8, 8, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 5,853,890\n",
      "Trainable params: 2,625,026\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows, img_cols = 256,256\n",
    "\n",
    "# Re-loads the MobileNet model without the top or FC layers\n",
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Here we freeze the last 4 layers \n",
    "# Layers are set to trainable as True by default\n",
    "for layer in MobileNet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(MobileNet.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "def addTopModelMobileNet(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# Set our class number to 3 (Young, Middle, Old)\n",
    "num_classes = 2\n",
    "\n",
    "FC_Head = addTopModelMobileNet(MobileNet, num_classes)\n",
    "\n",
    "model = Model(inputs = MobileNet.input, outputs = FC_Head)\n",
    "\n",
    "print(model.summary())\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"D:/Work/Courses/[code][FreeTutorials.Us] Udemy - Deep Learning Computer Vision/DeepLearningCV/Trained Models/monkey_breed_mobileNet.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Enter the number of training and validation samples here\n",
    "nb_train_samples = X_train.shape[0]\n",
    "nb_validation_samples = X_valid.shape[0]\n",
    "\n",
    "# We only train 5 EPOCHS \n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n",
      "241\n"
     ]
    }
   ],
   "source": [
    "print(nb_train_samples )\n",
    "print(nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 241 samples\n",
      "Epoch 1/15\n",
      "960/960 [==============================] - ETA: 1:04 - loss: 5.2887 - acc: 0.671 - ETA: 59s - loss: 6.6739 - acc: 0.585 - ETA: 51s - loss: 7.1356 - acc: 0.55 - ETA: 45s - loss: 6.9887 - acc: 0.56 - ETA: 40s - loss: 7.1524 - acc: 0.55 - ETA: 36s - loss: 7.2615 - acc: 0.54 - ETA: 32s - loss: 7.5194 - acc: 0.53 - ETA: 27s - loss: 7.4294 - acc: 0.53 - ETA: 23s - loss: 7.4154 - acc: 0.53 - ETA: 19s - loss: 7.5554 - acc: 0.53 - ETA: 15s - loss: 7.4638 - acc: 0.53 - ETA: 11s - loss: 7.4084 - acc: 0.54 - ETA: 7s - loss: 7.4585 - acc: 0.5373 - ETA: 3s - loss: 7.3755 - acc: 0.542 - 77s 80ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 2/15\n",
      "960/960 [==============================] - ETA: 55s - loss: 5.7924 - acc: 0.64 - ETA: 52s - loss: 6.9257 - acc: 0.57 - ETA: 47s - loss: 7.8912 - acc: 0.51 - ETA: 43s - loss: 7.4294 - acc: 0.53 - ETA: 39s - loss: 7.3539 - acc: 0.54 - ETA: 35s - loss: 7.0517 - acc: 0.56 - ETA: 31s - loss: 6.9797 - acc: 0.56 - ETA: 27s - loss: 7.1146 - acc: 0.55 - ETA: 23s - loss: 7.1916 - acc: 0.55 - ETA: 19s - loss: 7.4043 - acc: 0.54 - ETA: 15s - loss: 7.4867 - acc: 0.53 - ETA: 11s - loss: 7.3245 - acc: 0.54 - ETA: 7s - loss: 7.2648 - acc: 0.5493 - ETA: 3s - loss: 7.3215 - acc: 0.545 - 77s 80ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 3/15\n",
      "960/960 [==============================] - ETA: 53s - loss: 6.7998 - acc: 0.57 - ETA: 49s - loss: 7.6813 - acc: 0.52 - ETA: 45s - loss: 7.7233 - acc: 0.52 - ETA: 41s - loss: 8.0590 - acc: 0.50 - ETA: 37s - loss: 7.8072 - acc: 0.51 - ETA: 34s - loss: 7.6393 - acc: 0.52 - ETA: 30s - loss: 7.4834 - acc: 0.53 - ETA: 26s - loss: 7.6183 - acc: 0.52 - ETA: 22s - loss: 7.6953 - acc: 0.52 - ETA: 19s - loss: 7.6813 - acc: 0.52 - ETA: 15s - loss: 7.4638 - acc: 0.53 - ETA: 11s - loss: 7.4084 - acc: 0.54 - ETA: 7s - loss: 7.3229 - acc: 0.5457 - ETA: 3s - loss: 7.3215 - acc: 0.545 - 77s 80ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 4/15\n",
      "960/960 [==============================] - ETA: 53s - loss: 7.0517 - acc: 0.56 - ETA: 50s - loss: 7.1776 - acc: 0.55 - ETA: 46s - loss: 7.4714 - acc: 0.53 - ETA: 42s - loss: 7.4924 - acc: 0.53 - ETA: 38s - loss: 7.3035 - acc: 0.54 - ETA: 34s - loss: 7.1776 - acc: 0.55 - ETA: 30s - loss: 7.3035 - acc: 0.54 - ETA: 27s - loss: 7.2720 - acc: 0.54 - ETA: 23s - loss: 7.2755 - acc: 0.54 - ETA: 19s - loss: 7.2783 - acc: 0.54 - ETA: 15s - loss: 7.2577 - acc: 0.54 - ETA: 11s - loss: 7.3035 - acc: 0.54 - ETA: 7s - loss: 7.3810 - acc: 0.5421 - ETA: 3s - loss: 7.3935 - acc: 0.541 - 77s 80ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 5/15\n",
      "960/960 [==============================] - ETA: 53s - loss: 6.5480 - acc: 0.59 - ETA: 49s - loss: 6.0443 - acc: 0.62 - ETA: 46s - loss: 6.2961 - acc: 0.60 - ETA: 44s - loss: 6.7998 - acc: 0.57 - ETA: 40s - loss: 6.9006 - acc: 0.57 - ETA: 35s - loss: 7.0097 - acc: 0.56 - ETA: 31s - loss: 7.1956 - acc: 0.55 - ETA: 27s - loss: 7.3350 - acc: 0.54 - ETA: 23s - loss: 7.4994 - acc: 0.53 - ETA: 19s - loss: 7.3539 - acc: 0.54 - ETA: 15s - loss: 7.5096 - acc: 0.53 - ETA: 11s - loss: 7.4084 - acc: 0.54 - ETA: 7s - loss: 7.3810 - acc: 0.5421 - ETA: 3s - loss: 7.3395 - acc: 0.544 - 80s 83ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 6/15\n",
      "960/960 [==============================] - ETA: 53s - loss: 7.5554 - acc: 0.53 - ETA: 49s - loss: 6.7998 - acc: 0.57 - ETA: 46s - loss: 6.7998 - acc: 0.57 - ETA: 42s - loss: 7.1146 - acc: 0.55 - ETA: 38s - loss: 7.3539 - acc: 0.54 - ETA: 34s - loss: 7.5554 - acc: 0.53 - ETA: 30s - loss: 7.4834 - acc: 0.53 - ETA: 27s - loss: 7.5239 - acc: 0.53 - ETA: 23s - loss: 7.4994 - acc: 0.53 - ETA: 19s - loss: 7.5302 - acc: 0.53 - ETA: 15s - loss: 7.4638 - acc: 0.53 - ETA: 11s - loss: 7.4714 - acc: 0.53 - ETA: 7s - loss: 7.3616 - acc: 0.5433 - ETA: 3s - loss: 7.3575 - acc: 0.543 - 78s 81ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 7/15\n",
      "960/960 [==============================] - ETA: 54s - loss: 6.2961 - acc: 0.60 - ETA: 50s - loss: 6.9257 - acc: 0.57 - ETA: 46s - loss: 7.2196 - acc: 0.55 - ETA: 42s - loss: 6.8628 - acc: 0.57 - ETA: 38s - loss: 6.5480 - acc: 0.59 - ETA: 34s - loss: 6.8838 - acc: 0.57 - ETA: 30s - loss: 7.1596 - acc: 0.55 - ETA: 26s - loss: 7.2091 - acc: 0.55 - ETA: 23s - loss: 7.1076 - acc: 0.55 - ETA: 19s - loss: 7.1776 - acc: 0.55 - ETA: 15s - loss: 7.1890 - acc: 0.55 - ETA: 11s - loss: 7.2615 - acc: 0.54 - ETA: 7s - loss: 7.3616 - acc: 0.5433 - ETA: 3s - loss: 7.3935 - acc: 0.541 - 78s 81ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 8/15\n",
      "960/960 [==============================] - ETA: 54s - loss: 5.7924 - acc: 0.64 - ETA: 50s - loss: 6.7998 - acc: 0.57 - ETA: 46s - loss: 6.7159 - acc: 0.58 - ETA: 42s - loss: 6.9887 - acc: 0.56 - ETA: 39s - loss: 7.1524 - acc: 0.55 - ETA: 35s - loss: 7.2615 - acc: 0.54 - ETA: 31s - loss: 7.1596 - acc: 0.55 - ETA: 27s - loss: 7.1461 - acc: 0.55 - ETA: 23s - loss: 7.0237 - acc: 0.56 - ETA: 19s - loss: 7.0265 - acc: 0.56 - ETA: 15s - loss: 7.0975 - acc: 0.55 - ETA: 11s - loss: 7.0727 - acc: 0.56 - ETA: 7s - loss: 7.1679 - acc: 0.5553 - ETA: 3s - loss: 7.2316 - acc: 0.551 - 78s 81ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 9/15\n",
      "960/960 [==============================] - ETA: 58s - loss: 7.5554 - acc: 0.53 - ETA: 52s - loss: 7.6813 - acc: 0.52 - ETA: 47s - loss: 7.7233 - acc: 0.52 - ETA: 43s - loss: 7.3035 - acc: 0.54 - ETA: 39s - loss: 7.1020 - acc: 0.55 - ETA: 35s - loss: 7.3035 - acc: 0.54 - ETA: 31s - loss: 7.3035 - acc: 0.54 - ETA: 27s - loss: 7.3035 - acc: 0.54 - ETA: 23s - loss: 7.3035 - acc: 0.54 - ETA: 19s - loss: 7.2783 - acc: 0.54 - ETA: 15s - loss: 7.2119 - acc: 0.55 - ETA: 11s - loss: 7.2825 - acc: 0.54 - ETA: 7s - loss: 7.3616 - acc: 0.5433 - ETA: 3s - loss: 7.4114 - acc: 0.540 - 78s 81ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 10/15\n",
      "960/960 [==============================] - ETA: 54s - loss: 7.5554 - acc: 0.53 - ETA: 50s - loss: 8.1850 - acc: 0.49 - ETA: 46s - loss: 7.8912 - acc: 0.51 - ETA: 42s - loss: 7.6813 - acc: 0.52 - ETA: 38s - loss: 7.7065 - acc: 0.52 - ETA: 34s - loss: 7.6393 - acc: 0.52 - ETA: 30s - loss: 7.3395 - acc: 0.54 - ETA: 27s - loss: 7.3350 - acc: 0.54 - ETA: 23s - loss: 7.3315 - acc: 0.54 - ETA: 19s - loss: 7.3287 - acc: 0.54 - ETA: 15s - loss: 7.2577 - acc: 0.54 - ETA: 11s - loss: 7.3035 - acc: 0.54 - ETA: 7s - loss: 7.3035 - acc: 0.5469 - ETA: 3s - loss: 7.3575 - acc: 0.543 - 78s 81ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 11/15\n",
      "960/960 [==============================] - ETA: 54s - loss: 7.3035 - acc: 0.54 - ETA: 50s - loss: 6.9257 - acc: 0.57 - ETA: 46s - loss: 7.0517 - acc: 0.56 - ETA: 42s - loss: 7.4294 - acc: 0.53 - ETA: 38s - loss: 7.2028 - acc: 0.55 - ETA: 35s - loss: 7.2615 - acc: 0.54 - ETA: 31s - loss: 7.2316 - acc: 0.55 - ETA: 27s - loss: 7.3350 - acc: 0.54 - ETA: 23s - loss: 7.4714 - acc: 0.53 - ETA: 19s - loss: 7.5302 - acc: 0.53 - ETA: 15s - loss: 7.5096 - acc: 0.53 - ETA: 11s - loss: 7.3875 - acc: 0.54 - ETA: 7s - loss: 7.4004 - acc: 0.5409 - ETA: 3s - loss: 7.3575 - acc: 0.543 - 78s 81ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 12/15\n",
      "960/960 [==============================] - ETA: 54s - loss: 5.2887 - acc: 0.67 - ETA: 52s - loss: 6.7998 - acc: 0.57 - ETA: 47s - loss: 7.0517 - acc: 0.56 - ETA: 43s - loss: 7.8702 - acc: 0.51 - ETA: 39s - loss: 7.6057 - acc: 0.52 - ETA: 35s - loss: 7.5973 - acc: 0.52 - ETA: 31s - loss: 7.3755 - acc: 0.54 - ETA: 27s - loss: 7.3665 - acc: 0.54 - ETA: 23s - loss: 7.4714 - acc: 0.53 - ETA: 19s - loss: 7.3791 - acc: 0.54 - ETA: 15s - loss: 7.4180 - acc: 0.53 - ETA: 11s - loss: 7.2825 - acc: 0.54 - ETA: 7s - loss: 7.3616 - acc: 0.5433 - ETA: 3s - loss: 7.3935 - acc: 0.541 - 79s 82ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 13/15\n",
      "960/960 [==============================] - ETA: 55s - loss: 7.0517 - acc: 0.56 - ETA: 51s - loss: 8.1850 - acc: 0.49 - ETA: 46s - loss: 8.3948 - acc: 0.47 - ETA: 42s - loss: 8.4998 - acc: 0.47 - ETA: 39s - loss: 8.5627 - acc: 0.46 - ETA: 35s - loss: 8.2689 - acc: 0.48 - ETA: 31s - loss: 7.9871 - acc: 0.50 - ETA: 27s - loss: 8.1535 - acc: 0.49 - ETA: 23s - loss: 8.1150 - acc: 0.49 - ETA: 19s - loss: 7.8324 - acc: 0.51 - ETA: 15s - loss: 7.8301 - acc: 0.51 - ETA: 11s - loss: 7.6603 - acc: 0.52 - ETA: 7s - loss: 7.5554 - acc: 0.5312 - ETA: 3s - loss: 7.4834 - acc: 0.535 - 78s 81ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 14/15\n",
      "960/960 [==============================] - ETA: 54s - loss: 6.7998 - acc: 0.57 - ETA: 50s - loss: 6.7998 - acc: 0.57 - ETA: 46s - loss: 7.3875 - acc: 0.54 - ETA: 42s - loss: 7.5554 - acc: 0.53 - ETA: 38s - loss: 7.6057 - acc: 0.52 - ETA: 34s - loss: 7.1356 - acc: 0.55 - ETA: 31s - loss: 7.1956 - acc: 0.55 - ETA: 27s - loss: 7.2406 - acc: 0.55 - ETA: 23s - loss: 7.2475 - acc: 0.55 - ETA: 19s - loss: 7.3035 - acc: 0.54 - ETA: 15s - loss: 7.2806 - acc: 0.54 - ETA: 11s - loss: 7.1986 - acc: 0.55 - ETA: 7s - loss: 7.2648 - acc: 0.5493 - ETA: 3s - loss: 7.2855 - acc: 0.548 - 78s 82ms/step - loss: 7.3875 - acc: 0.5417 - val_loss: 7.1562 - val_acc: 0.5560\n",
      "Epoch 15/15\n",
      "704/960 [=====================>........] - ETA: 54s - loss: 7.5554 - acc: 0.53 - ETA: 50s - loss: 8.1850 - acc: 0.49 - ETA: 48s - loss: 8.2269 - acc: 0.48 - ETA: 43s - loss: 7.8702 - acc: 0.51 - ETA: 39s - loss: 8.0087 - acc: 0.50 - ETA: 35s - loss: 7.8072 - acc: 0.51 - ETA: 31s - loss: 7.7352 - acc: 0.52 - ETA: 27s - loss: 7.7442 - acc: 0.51 - ETA: 23s - loss: 7.6953 - acc: 0.52 - ETA: 19s - loss: 7.8324 - acc: 0.51 - ETA: 15s - loss: 7.5783 - acc: 0.5298"
     ]
    }
   ],
   "source": [
    "# history = model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch = nb_train_samples // batch_size,\n",
    "#     epochs = epochs,\n",
    "#     callbacks = callbacks,\n",
    "#     validation_data = validation_generator,\n",
    "#     validation_steps = nb_validation_samples // batch_size)\n",
    "history = model.fit(X_train, Y_train,batch_size=batch_size,  epochs=epochs, verbose=1,validation_data=(X_valid, Y_valid),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "opt = keras.optimizers.Adam(lr=0.0001, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 254, 254, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 252, 252, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 252, 252, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 122, 122, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 122, 122, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 476288)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               243859968 \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 244,031,970\n",
      "Trainable params: 244,030,178\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "#rms = RMSprop()\n",
    "#sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2_2\n",
    "#visible = (256,256,1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5,5) ,name='conv1_1', input_shape = input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2\n",
    "model.add(Conv2D(64, (5, 5), name='conv2_1'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "\n",
    "#rms = RMSprop()\n",
    "#sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_1 (Conv2D)             (None, 252, 252, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 252, 252, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 248, 248, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 248, 248, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 120, 120, 64)      51264     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 116, 116, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 116, 116, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 58, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 58, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 215296)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               110232064 \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 110,414,882\n",
      "Trainable params: 110,414,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model 2\n",
    "#visible = (256,256,1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5,5) ,name='conv1_1', input_shape = input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, (5, 5),name='conv1_2'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2\n",
    "model.add(Conv2D(64, (5, 5), name='conv2_1'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (5, 5), name='conv2_2'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "\n",
    "#rms = RMSprop()\n",
    "#sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 245, 245, 16)      6928      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 122, 122, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 115, 115, 64)      65600     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 112, 112, 64)      65600     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 109, 109, 128)     131200    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 106, 106, 256)     524544    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 53, 53, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 719104)            0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               92045440  \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 92,847,698\n",
      "Trainable params: 92,847,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model 3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(12,12), activation='relu', padding='valid', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#bat1 = BatchNormalization(axis = 1)(pool1)\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(8,8), activation='relu', padding='valid'))\n",
    "model.add(Conv2D(64, kernel_size=(4,4), activation='relu', padding='valid'))\n",
    "model.add(Conv2D(128, kernel_size=(4,4), activation='relu', padding='valid'))\n",
    "model.add(Conv2D(256, kernel_size=(4,4), activation='relu', padding='valid'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "#output = Dense(1, activation='sigmoid')(flat)\n",
    "#model = Model(inputs=visible, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AvgPooling2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-441411cebbad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# let's train the model using SGD + momentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-441411cebbad>\u001b[0m in \u001b[0;36mcnn_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m                      activation='relu'))\n\u001b[0;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAvgPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m#     model.add(Dropout(0.2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AvgPooling2D' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=input_shape,\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "# let's train the model using SGD + momentum\n",
    "lr = 0.00001\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,715,234\n",
      "Trainable params: 3,715,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MODEL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "# COMPILE\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"D:/Work/Final Project/Code and Dataset/experimentation/saved_checkpoints/review 1-Copy9-CNN5-Copy3_1.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 6,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 960 samples, validate on 241 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "960/960 [==============================] - ETA: 48s - loss: 0.6959 - acc: 0.49 - ETA: 33s - loss: 1.5528 - acc: 0.50 - ETA: 23s - loss: 1.8396 - acc: 0.49 - ETA: 16s - loss: 1.5789 - acc: 0.49 - ETA: 11s - loss: 1.4167 - acc: 0.48 - ETA: 6s - loss: 1.2982 - acc: 0.4883 - ETA: 2s - loss: 1.2182 - acc: 0.477 - 34s 35ms/step - loss: 1.1840 - acc: 0.4724 - val_loss: 0.7018 - val_acc: 0.4979\n",
      "Epoch 2/20\n",
      "960/960 [==============================] - ETA: 22s - loss: 0.7010 - acc: 0.47 - ETA: 20s - loss: 0.6949 - acc: 0.48 - ETA: 17s - loss: 0.6950 - acc: 0.49 - ETA: 13s - loss: 0.6956 - acc: 0.49 - ETA: 9s - loss: 0.6959 - acc: 0.5031 - ETA: 5s - loss: 0.6959 - acc: 0.498 - ETA: 1s - loss: 0.6957 - acc: 0.496 - 28s 29ms/step - loss: 0.6954 - acc: 0.4948 - val_loss: 0.6917 - val_acc: 0.5062\n",
      "Epoch 3/20\n",
      "960/960 [==============================] - ETA: 18s - loss: 0.6917 - acc: 0.51 - ETA: 16s - loss: 0.6910 - acc: 0.52 - ETA: 15s - loss: 0.6913 - acc: 0.51 - ETA: 12s - loss: 0.6906 - acc: 0.52 - ETA: 8s - loss: 0.6907 - acc: 0.5195 - ETA: 4s - loss: 0.6906 - acc: 0.517 - ETA: 1s - loss: 0.6902 - acc: 0.515 - 26s 27ms/step - loss: 0.6894 - acc: 0.5156 - val_loss: 0.6868 - val_acc: 0.5207\n",
      "Epoch 4/20\n",
      "960/960 [==============================] - ETA: 17s - loss: 0.6791 - acc: 0.53 - ETA: 14s - loss: 0.6832 - acc: 0.52 - ETA: 12s - loss: 0.6835 - acc: 0.53 - ETA: 9s - loss: 0.6836 - acc: 0.5293 - ETA: 7s - loss: 0.6844 - acc: 0.530 - ETA: 4s - loss: 0.6837 - acc: 0.534 - ETA: 1s - loss: 0.6841 - acc: 0.535 - 25s 26ms/step - loss: 0.6845 - acc: 0.5323 - val_loss: 0.6866 - val_acc: 0.5560\n",
      "Epoch 5/20\n",
      "896/960 [===========================>..] - ETA: 23s - loss: 0.7074 - acc: 0.50 - ETA: 19s - loss: 0.6958 - acc: 0.54 - ETA: 14s - loss: 0.6885 - acc: 0.56 - ETA: 11s - loss: 0.6853 - acc: 0.56 - ETA: 7s - loss: 0.6826 - acc: 0.5648 - ETA: 4s - loss: 0.6815 - acc: 0.567 - ETA: 1s - loss: 0.6793 - acc: 0.5787"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1,validation_data=(X_valid, Y_valid),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.6919137892386725\n",
      "accuracy= 0.5601659768349897\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_valid, Y_valid, verbose=0)\n",
    "print('loss= ' + str(score[0]))\n",
    "print('accuracy= ' + str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting our loss charts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_loss_values, label='Validation/Test Loss')\n",
    "line2 = plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting our accuracy charts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_acc_values, label='Validation/Test Accuracy')\n",
    "line2 = plt.plot(epochs, acc_values, label='Training Accuracy')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       107\n",
      "           1       0.56      1.00      0.72       134\n",
      "\n",
      "    accuracy                           0.56       241\n",
      "   macro avg       0.78      0.50      0.37       241\n",
      "weighted avg       0.75      0.56      0.41       241\n",
      "\n",
      "[[  1 106]\n",
      " [  0 134]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict_classes(X_valid)\n",
    "\n",
    "print(classification_report(np.argmax(Y_valid,axis=1), y_pred))\n",
    "print(confusion_matrix(np.argmax(Y_valid,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-dcc5728ecdf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#model_loaded = load_model('/Users/shubh/Desktop/Final Project/Code and Dataset/experimentation/saved_checkpoints/review1-copy6_1.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclass_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_generator' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "img_row, img_height, img_depth = 32,32,3\n",
    "#model_loaded = load_model('/Users/shubh/Desktop/Final Project/Code and Dataset/experimentation/saved_checkpoints/review1-copy6_1.h5')\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "nb_train_samples = 41322\n",
    "nb_validation_samples = 13877\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "target_names = list(class_labels.values())\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of misclassifed data are: \n",
      "\n",
      "(array([  0,   1,   2,   3,   4,   7,  11,  12,  13,  14,  15,  18,  19,\n",
      "        20,  22,  23,  27,  30,  31,  32,  33,  34,  35,  37,  42,  43,\n",
      "        44,  45,  47,  50,  51,  52,  54,  56,  59,  60,  61,  63,  64,\n",
      "        65,  69,  70,  72,  74,  75,  76,  78,  79,  80,  82,  84,  86,\n",
      "        88,  90,  91,  93,  96, 103, 105, 106, 109, 111, 113, 115, 116,\n",
      "       119], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# loads the MNIST dataset\n",
    "#(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n",
    "\n",
    "# Use numpy to create an array that stores a value of 1 when a misclassification occurs\n",
    "result = np.absolute(np.argmax(Y_valid,axis=1) - y_pred)\n",
    "result_indices = np.nonzero(result > 0)\n",
    "\n",
    "#  Display the indices of mislassifications\n",
    "print(\"Indices of misclassifed data are: \\n\\n\" + str(result_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "#from keras.models import load_model\n",
    "\n",
    "#classifier = load_model('/home/deeplearningcv/DeepLearningCV/Trained Models/mnist_simple_cnn.h5')\n",
    "\n",
    "def draw_test(name, pred, input_im, true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(input_im, 0, 0, 0, imageL.shape[0]*2 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    expanded_image = cv2.cvtColor(expanded_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(expanded_image, str(pred), (152, 70) , cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,255,0), 2)\n",
    "    cv2.putText(expanded_image, str(true_label), (250, 70) , cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "for i in range(0,10):\n",
    "\n",
    "    input_im = X_valid[result_indices[0][i]]\n",
    "    #print(y_test[result_indices[0][i]])\n",
    "    imageL = cv2.resize(input_im, None, fx=4, fy=4, interpolation = cv2.INTER_CUBIC) \n",
    "    input_im = input_im.reshape(1,128,128,1) \n",
    "    \n",
    "    ## Get Prediction\n",
    "    res = str(model.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "    draw_test(\"Prediction\", res, imageL, Y_valid[result_indices[0][i]]) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
